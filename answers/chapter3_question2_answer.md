# Grammar Concepts: Ambiguity, Left Recursion, and Left Factoring\n\nThis document explains three important concepts related to context-free grammars: ambiguity, left recursion, and left factoring, with suitable examples for each.\n\n---\n\n## a) Ambiguity in Grammars\n\n**Definition:**\nA grammar is said to be **ambiguous** if there exists at least one string in the language generated by the grammar that has more than one distinct parse tree (or equivalently, more than one distinct leftmost derivation or more than one distinct rightmost derivation).\n\nAn ambiguous grammar can lead to problems in compilers because the syntactic structure of a program should ideally be unique to ensure its meaning is also unique. If a statement can be parsed in multiple ways, it implies multiple interpretations of its structure and potentially its semantics.\n\n**Causes of Ambiguity:**\nAmbiguity often arises from productions that allow the same sequence of terminals to be generated through different structural choices, particularly with expressions involving operators that have precedence and associativity rules.\n\n**Example of an Ambiguous Grammar:**\nConsider the classic ambiguous grammar for arithmetic expressions involving addition and multiplication:\n\n```\nG1: E → E + E | E * E | (E) | id\n```\n\nLet's try to parse the string `id + id * id` using this grammar.\n\n**Parse Tree 1 (Multiplication before Addition - incorrect precedence):**\n```\n      E\n     /|\\\n    E +  E\n    |   /|\\\n   id  E * E\n       |   |\n      id  id\n```\nThis corresponds to the derivation (LMD shown, implies (id + id) * id):\nE ⇒ E + E\n  ⇒ id + E\n  ⇒ id + E * E\n  ⇒ id + id * E\n  ⇒ id + id * id\n\n**Parse Tree 2 (Addition before Multiplication - correct precedence):**\n```\n        E\n       /|\\\n      E *  E\n     /|\\   |\n    E + E  id\n    |   |\n   id  id\n```\nThis corresponds to the derivation (LMD shown, implies id + (id * id)):\nE ⇒ E * E\n  ⇒ E + E * E  (Incorrect LMD shown here, let me correct the derivation path for tree 2)\n  Let's use another LMD for Tree 2 that leads to `id + (id * id)` if we enforce an unambiguous version. The ambiguity lies in G1 not enforcing precedence.\n\nLet's re-do the derivations for string `id + id * id` for G1:\n\n**Derivation 1 (LMD implies (id + id) * id ):**\nE ⇒ E + E\n  ⇒ id + E\n  ⇒ id + E * E  (Mistake here: this should be `id + E` then `id + id` then this `id` expands to `E*E` to get the first tree. Let me correct the LMD for the first parse tree)\n\n**Corrected LMD for Parse Tree 1 ( (id + id) * id ):**\nE ⇒ E * E \n  ⇒ E + E * E \n  ⇒ id + E * E \n  ⇒ id + id * E \n  ⇒ id + id * id\n*(This LMD implies (id + id) * id which matches the structure of Parse Tree 1 if `E + E` is derived from the first E of `E * E`)*\n
**Corrected LMD for Parse Tree 2 ( id + (id * id) ):**\nE ⇒ E + E \n  ⇒ id + E \n  ⇒ id + E * E \n  ⇒ id + id * E \n  ⇒ id + id * id\n*(This LMD implies id + (id*id) which matches the structure of Parse Tree 2 if `E*E` is derived from the second E of `E+E`)*

Actually, the LMDs for an ambiguous grammar are more direct. Let's trace it clearly:
String: `id + id * id`
Grammar: `E → E + E | E * E | (E) | id`

**LMD 1 (Interpreting as (id + id) * id):**
`E ⇒ E * E` (Rule `E → E * E`)
  `⇒ E + E * E` (Rule `E → E + E` for the leftmost E)
  `⇒ id + E * E` (Rule `E → id` for the new leftmost E)
  `⇒ id + id * E` (Rule `E → id` for the new leftmost E)
  `⇒ id + id * id` (Rule `E → id` for the last E)
*This structure corresponds to `(id + id) * id`.* 
 (The first parse tree shown earlier was more like `E -> E+E -> id + E -> id + E*E -> id + id*E -> id + id*id` if we map rules. Let me redraw the parse tree for *this* derivation.)

**Parse Tree for LMD 1 ((id + id) * id):**
```
      E
     /|\\ 
    E * E
   /|\\  |
  E + E id
  |   |
 id  id 
```

**LMD 2 (Interpreting as id + (id * id)):**
`E ⇒ E + E` (Rule `E → E + E`)
  `⇒ id + E` (Rule `E → id` for the leftmost E)
  `⇒ id + E * E` (Rule `E → E * E` for the remaining E)
  `⇒ id + id * E` (Rule `E → id` for the new leftmost E)
  `⇒ id + id * id` (Rule `E → id` for the last E)
*This structure corresponds to `id + (id * id)`.* 

**Parse Tree for LMD 2 (id + (id * id)):**
```
      E
     /|\\ 
    E + E
    |  /|\\ 
   id E * E
      |   |
     id  id 
```

Since the string `id + id * id` has two different leftmost derivations (and thus two different parse trees), the grammar G1 is ambiguous. Ambiguity can be resolved by rewriting the grammar to enforce precedence and associativity, often by introducing more non-terminal levels (e.g., E for addition, T for multiplication, F for factors).

---

## b) Left Recursion\n\n**Definition:**\nA production in a grammar is said to be **left-recursive** if the leftmost symbol on its right-hand side is the same as the non-terminal on its left-hand side. A grammar containing at least one left-recursive production is called a left-recursive grammar.\n\nThere are two types:
1.  **Direct Left Recursion:** A production of the form `A → Aα`, where A is a non-terminal and α is a string of terminals and/or non-terminals.
2.  **Indirect Left Recursion (or Mutual Left Recursion):** Occurs when two or more non-terminals are defined in terms of each other in a way that can lead back to the original non-terminal on the left. For example:
    `A → Bα | ...`
    `B → Aβ | ...`
    This can lead to a derivation like A ⇒ Bα ⇒ Aβα.

**Problems with Left Recursion:**\nLeft recursion is problematic for top-down parsers (like Recursive Descent Parsers or LL parsers) because they can enter an infinite loop. When trying to expand a non-terminal `A` using a rule `A → Aα`, the parser would immediately try to expand `A` again, leading to an endless recursion without consuming any input tokens.\n\n**Example of Direct Left Recursion:**\n```\nG2: E → E + T | T\n    T → id
```\nThe production `E → E + T` is directly left-recursive because `E` appears as the leftmost symbol on the RHS.\n
**Eliminating Direct Left Recursion:**\nDirect left recursion can be eliminated by transforming the productions. If we have:
`A → Aα₁ | Aα₂ | ... | Aαₘ | β₁ | β₂ | ... | βₙ`
(where βᵢ do not start with A)

This can be replaced by:
`A → β₁A' | β₂A' | ... | βₙA'`
`A' → α₁A' | α₂A' | ... | αₘA' | ε`

**Applying to G2:**
For `E → E + T | T`:
*   α₁ = `+ T`
*   β₁ = `T`

The transformed grammar G2' becomes:
```\nG2': E  → T E'\n     E' → + T E' | ε\n     T  → id
```
This grammar G2' is not left-recursive and generates the same language as G2. It is suitable for top-down parsing.

---

## c) Left Factoring\n\n**Definition:**\n**Left factoring** is a grammar transformation technique used to eliminate common prefixes from the right-hand sides of productions for a given non-terminal. It is primarily used to make a grammar suitable for predictive parsing (like LL(1) parsing) by ensuring that the parser can decide which production to use by looking at only the next input token (the lookahead token).\n\nIf a non-terminal `A` has multiple productions that start with the same sequence of symbols (a common prefix), say:
`A → αβ₁ | αβ₂ | ... | αβₙ`
(where α is the common prefix, and βᵢ are the differing suffixes, and n ≥ 2)

The parser would not know which production to choose by just seeing α in the input. Left factoring modifies these productions to defer the decision.

**Transformation Rule:**\nThe productions `A → αβ₁ | αβ₂ | ... | αβₙ | γ` (where γ represents other productions for A that don't start with α) are transformed into:
`A → αA' | γ`
`A' → β₁ | β₂ | ... | βₙ`

Here, `A'` is a new non-terminal. The parser first recognizes α, then uses `A'` to decide among the suffixes βᵢ.

**Example of Left Factoring:**\nConsider the grammar segment:
```\nG3: S → if E then S else S | if E then S | other_stuff
```\nHere, the non-terminal `S` has two productions starting with the common prefix `if E then S`:
*   `if E then S else S`
*   `if E then S`

**Applying Left Factoring:**
*   Common prefix α = `if E then S`
*   For the first rule: β₁ = `else S`
*   For the second rule: β₂ = `ε` (since `if E then S` is a complete RHS matching the prefix)
*   γ = `other_stuff`

We introduce a new non-terminal, say `S'`.
The transformed grammar G3' becomes:
```\nG3': S  → if E then S S' | other_stuff\n     S' → else S | ε
```
Now, after seeing `if E then S`, the parser looks for `S'`. If it sees `else`, it chooses `S' → else S`. If it sees something else that can follow S (e.g., from FOLLOW(S)), it can choose `S' → ε`.

Left factoring helps in creating grammars where the choice of production can be made deterministically with a limited lookahead, which is a requirement for LL(k) parsers (especially LL(1) parsers). 