# Grammar Concepts: Ambiguity, Left Recursion, and Left Factoring

This document explains three important concepts in grammar design: Ambiguity, Left Recursion, and Left Factoring, with suitable examples.

---

## a) Ambiguity

### Definition

A **grammar is ambiguous** if there exists at least one string in the language that can be generated by the grammar in more than one way. This means the string has multiple parse trees or multiple leftmost (or rightmost) derivations.

Ambiguity is problematic in compiler design because it leads to uncertainty in how to interpret a program construct, making it impossible to determine the intended meaning uniquely.

### Example of Ambiguous Grammar

Consider the following grammar for arithmetic expressions:

```
E → E + E
E → E * E  
E → (E)
E → id
```

**Ambiguous String:** `id + id * id`

This string can be parsed in two different ways:

**Parse Tree 1:** (Addition first)
```
        E
      / | \
     E  +  E
     |   / | \
    id  E  *  E
        |     |
       id    id
```

**Parse Tree 2:** (Multiplication first)
```
        E
      / | \
     E  *  E
   / | \   |
  E  +  E  id
  |     |
 id    id
```

**Different Derivations:**

*Leftmost Derivation 1:*
```
E ⇒ E + E ⇒ id + E ⇒ id + E * E ⇒ id + id * E ⇒ id + id * id
```

*Leftmost Derivation 2:*
```
E ⇒ E * E ⇒ E + E * E ⇒ id + E * E ⇒ id + id * E ⇒ id + id * id
```

### Resolving Ambiguity

**Method 1: Rewrite the Grammar**
```
E → E + T | T
T → T * F | F
F → (E) | id
```

**Method 2: Use Precedence and Associativity Rules**
- Specify that `*` has higher precedence than `+`
- Specify left associativity for operators of same precedence

---

## b) Left Recursion

### Definition

A grammar is **left recursive** if there is a non-terminal A such that there is a derivation A ⇒⁺ Aα for some string α. In simpler terms, a production is left recursive if the leftmost symbol on the right-hand side is the same as the left-hand side non-terminal.

Left recursion causes problems for top-down parsers (like recursive descent parsers) because they can enter infinite loops.

### Types of Left Recursion

**1. Immediate Left Recursion**
```
A → Aα | β
```
Where A appears immediately as the first symbol on the right-hand side.

**2. Indirect Left Recursion**
```
A → Bα
B → Aβ | γ
```
Where A eventually derives a string starting with A through other non-terminals.

### Example of Left Recursive Grammar

```
E → E + T | T
T → T * F | F
F → (E) | id
```

Here, `E → E + T` and `T → T * F` are left recursive productions.

### Eliminating Immediate Left Recursion

**General Form:**
```
A → Aα₁ | Aα₂ | ... | Aαₘ | β₁ | β₂ | ... | βₙ
```

**Transformed Form:**
```
A → β₁A' | β₂A' | ... | βₙA'
A' → α₁A' | α₂A' | ... | αₘA' | ε
```

**Example Transformation:**
Original:
```
E → E + T | T
```

After eliminating left recursion:
```
E → TE'
E' → +TE' | ε
```

### Eliminating Indirect Left Recursion

**Algorithm:**
1. Arrange non-terminals in some order A₁, A₂, ..., Aₙ
2. For i = 1 to n do:
   - For j = 1 to i-1 do:
     - Replace each production Aᵢ → Aⱼγ with Aᵢ → δ₁γ | δ₂γ | ... | δₖγ
       where Aⱼ → δ₁ | δ₂ | ... | δₖ are all current Aⱼ productions
   - Eliminate immediate left recursion among Aᵢ productions

---

## c) Left Factoring

### Definition

**Left factoring** is a grammar transformation technique used when it is not clear which of two alternative productions to use to expand a non-terminal. This occurs when two or more productions for the same non-terminal have a common prefix.

Left factoring is necessary for predictive parsing, where the parser must decide which production to use based on the current input symbol.

### When Left Factoring is Needed

When we have productions of the form:
```
A → αβ₁ | αβ₂ | ... | αβₙ | γ
```

Where α is the common prefix, and the parser cannot decide which production to choose when it sees the beginning of α.

### Example of Grammar Requiring Left Factoring

```
S → if E then S else S | if E then S | a
```

Here, both productions for S start with "if E then S", making it impossible for a predictive parser to decide which production to use when it encounters "if".

### Left Factoring Algorithm

**Step 1:** Identify the longest common prefix α of two or more productions.

**Step 2:** Replace the productions:
```
A → αβ₁ | αβ₂ | ... | αβₙ | γ
```

With:
```
A → αA' | γ
A' → β₁ | β₂ | ... | βₙ
```

Where A' is a new non-terminal.

### Example Transformation

**Original Grammar:**
```
S → if E then S else S | if E then S | a
```

**After Left Factoring:**
```
S → if E then S S' | a
S' → else S | ε
```

### Another Example

**Original:**
```
A → abB | abC | aD
```

**Step 1:** Common prefix is "a"
```
A → aA'
A' → bB | bC | D
```

**Step 2:** A' still has common prefix "b"
```
A → aA'
A' → bA'' | D
A'' → B | C
```

---

## Importance in Parser Design

### For Top-Down Parsers:
- **Left Recursion:** Must be eliminated to prevent infinite loops
- **Left Factoring:** Required for predictive parsing to work correctly
- **Ambiguity:** Must be resolved to ensure deterministic parsing

### For Bottom-Up Parsers:
- **Left Recursion:** Generally not a problem
- **Ambiguity:** Can cause shift-reduce or reduce-reduce conflicts
- **Left Factoring:** Less critical but can help in some cases

### Summary

1. **Ambiguity** creates multiple interpretations of the same string
2. **Left Recursion** causes infinite loops in top-down parsers
3. **Left Factoring** enables predictive parsing by removing common prefixes

All three concepts are crucial for designing grammars that can be efficiently and unambiguously parsed by compiler tools. 